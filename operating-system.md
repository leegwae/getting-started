# operating-system

> 질문과 답변은 [이 레포지토리](https://github.com/leegwae/operating-system)에 정리된 텍스트에 기반합니다. 자세한 내용은 해당 레포지토리를 참고하세요.

## TOC

- [운영체제 기본](#운영체제-기본)
- [인터럽트](#인터럽트)
- [프로세스](#프로세스)
- [스레드](#스레드)
- [프로세스 동기화](#프로세스-동기화)
- [데드락](#데드락)
- [메모리 관리](#메모리-관리)
- [가상 메모리](#가상-메모리)

## 운영체제 기본

### 운영체제의 역할에 대해 아는대로 말해보세요

운영체제는 첫번째, 복잡한 하드웨어를 추상화하여 시스템 콜의 형태로 응용 프로그램에게 제공한다. 두번째 메모리, I/O 디바이스와 같은 컴퓨터 자원을 관리하여 프로그램에게 할당 및 분배한다.

### CPU의 이중 모드에 대해 설명해주세요

CPU는 커널 모드와 사용자 모드를 가진다. 운영체제는 커널 모드에서, 사용자 프로그램은 사용자 모드에서 실행된다.

### 이중 모드가 필요한 이유는 무엇인가요?

이중 모드는 사용자로부터 시스템을 보호하기 위해 필요하다. 특권 명령이 커널 모드에서만 실행되도록 하여 악의적인 사용자 프로그램이 다른 사용자 프로그램을 종료시키거나, 자신에게 할당되지 않은 메모리에 접근하는 것을 막는다.

## 인터럽트

 ### 인터럽트란 무엇인가?

CPU에게 특정 이벤트의 발생을 알려 현재 실행 중인 프로세스의 실행을 중단하고 해당 이벤트를 처리하도록 요청하는 것이다.

### 인터럽트가 발생하고 처리되는 과정에 대해 말해보세요

첫번째, 하드웨어나 소프트웨어가 인터럽트 라인을 설정한다. 두번째, CPU는 현재 명령어(PC가 가리키고 있는 명령어)를 수행한 후 다음 명령어를 수행하기 전 인터럽트 라인을 검사하여 인터럽트의 발생을 확인한다. 세번째, CPU가 프로세스의 상태를 스택에 저장(레지스터를 스택에 저장->프로그램 카운터를 스택에 저장->스택 포인터 옮김)하고 커널 모드로 전환한다. 네번째, 인터럽트 벡터 테이블에서 인터럽트 핸들러를 찾아 메모리에 적재하고 실행한다. 다섯번째, 저장했던 상태를 복구하고 사용자 모드로 전환하여 다음 명령어를 실행한다.

### 인터럽트 서비스 루틴 실행 중 다른 인터럽트가 걸리면 어떻게 할까?

인터럽트의 우선 순위에 따라서 다른 인터럽트를 수행할지 말지 결정한다.

## 프로세스

### 프로세스란 무엇인가

RAM에 적재되어 실행 중인 프로그램으로 CPU로부터 자원을 할당받는다.

### 프로세스는 RAM에 어떤 구조로 적재되어있는지 말해보세요(프로세스 주소 공간에 대해 설명해주세요)

프로세스는 RAM에 코드 세그먼트, 데이터 세그먼트, 스택 세그먼트로 나뉘어 저장된다. 코드 세그먼트는 실행 가능한 코드와 읽기 전용 상수들을 저장한다. 데이터 세그먼트는 전역 변수를 저장한다. 스택은 함수와 관련한 데이터(매개변수, 지역 변수)를 저장한다. 이때 데이터 세그먼트와 스택 사이에 빈 공간(힙)이 있는데 동적 메모리를 할당할 때 사용한다.

### 동시성과 병렬성에 대해 설명해주세요?

동시성(concurrency)은 한 개의 코어로 여러 개의 연산을 번걸아가며 수행하는 것이다. 병렬성(Parallelism)은 여러 개의 코어로 여러 개의 연산을 동시에 수행하는 것이다.

### 멀티 프로세스란 무엇인가요?

하나의 CPU가 여러 개의 프로세스를 번갈아가면서 실행하는 것이다.

### 왜 멀티 프로세스를 사용하는가?

첫번째, 사용자에게 여러 개의 프로세스가 블로킹되지 않고 실행되는 것처럼 보이기 위해서이다. 두번째, CPU를 효율적으로 사용하기 위해서이다.

### CPU를 효율적으로 사용하기에 멀티 프로세스가 왜 좋은가?

오늘날 CPU는 디스크에 비해 속도가 매우 빠르며 프로세스는 대부분 I/O를 기다리는 I/O 바운드 프로세스이다. 블록된 동안 CPU 작업을 필요로 하는 다른 프로세스를 실행한다면 CPU 자원을 낭비하지 않을 수 있다.

### 문맥 교환에 대해 설명해주세요

문맥 교환은 실행 중인 프로세스의 상태를 PCB에 적재하고, 실행하려는 프로세스의 정보를 PCB에서 읽어 레지스터에 적재하는 것이다.

### PCB에 대해 설명해주세요

PCB(Process Control Block)은 프로그램을 실행하기 위해 필요한 정보를 저장한다. 프로세스의 id, PC, 상태 비트, 레지스터 등을 가진다.

### 프로세스 상태에 대해 설명해주세요

프로세스가 메모리에 적재되어 실행을 대기하는 `ready` 상태, CPU 자원을 할당받아 실행 중인 `running` 상태, 이벤트(예: I/O)의 발생을 대기 중인 `waiting` 상태, 특정 이유로(예: 메모리 부족) 디스크의 swap 영역으로 swap out된 `suspended` 상태, 모든 자원을 반납하고 실행이 종료된 `terminated` 상태가 있다.

### 선점 스케줄링과 비선점 스케줄링의 차이는 무엇인가?

선점 스케줄링에서는 프로세스가 실행 도중에 CPU 자원을 다른 프로세스에게 할당 가능하다. 비선점 스케줄링에서는 프로세스는 종료 혹은 대기 상태가 되기 전까지 CPU 자원을 독점한다.

### 선점 스케줄링을 사용하기에 적합한 환경의 예시를 들어주세요

선점 스케줄링은 다수의 사용자에게 빠르게 응답하는 것이 중요할 때 사용하기 좋다. (하나의 프로세스가 CPU를 독점하면 안되므로 뺏어야된다.)

### 비선점 스케줄링의 종류와 각각의 장점과 단점에 대해 설명해주세요?

FCFS(First-come First-served)프로세스가 요청한 순서대로 큐에 삽입되고 실행된다. 간단하지만 수행 시간이 짧은 프로세스가 뒤로 가게 되면 프로세스들의 평균 대기 시간이 증가한다. SJF(Shortest Job First)는 프로세스 중 수행 시간이 짧은 프로세스가 먼저 실행된다. 평균 대기 시간이 가장 짧으나 프로세스의 수행 시간을 미리 알기 어렵고 수행 시간이 긴 프로세스가 기아 상태에 빠질 수 있다. HRRN(Highest Response Ratio Next)는 response ratio(`(대기 시간 + 수행 시간)/(수행 시간)`)가 높은 순서대로 먼저 실행된다. 기아 문제를 해결한다. 우선순위 스케줄링은 우선순위가 높은 프로세스가 먼저 실행된다. 우선순위가 낮은 프로세스가 기아 상태에 빠질 수 있다.

### 선점 스케줄링의 종류와 각각의 장점과 단점에 대해 설명해주세요?

SRTN(Shortest Remaining Time Next)는 SFJ의 선점 구현이다. 평균 대기 시간은 줄어드나 수행 시간이 긴 프로세스가 기아 상태에 빠질 수 있다. RR(Round Robin)은 프로세스가 모두 일정한 시간을 할당받아 번갈아가며 실행된다. 할당 시간을 크게 주면 뒤쪽 순서의 프로세스가 대기하는 시간이 늘어난다. 작게 주면 응답은 빠르지만 문맥 교환으로 인한 오버헤드가 증가한다. 다단계 큐는 우선순위가 같은 프로세스들끼리 동일한 큐에 넣고 각 큐는 독자적인 스케줄링을 가진다. 더 높은 우선순위의 큐가 비어야 낮은 우선순위의 큐를 작업하기 때문에 기아 문제가 발생할 수 있다. 다단계 피드백 큐는 기다린 시간에 따라 우선순위를 높게 주는 다단계 큐이다. 기아 문제를 예방할 수 있다.

## 스레드

### 멀티 스레드가 무엇인가요

하나의 프로세스가 여러 개의 독립적인 실행 흐름인 스레드로 구성되는 것이다. 이때 운영체제는 프로세스가 아니라 스레드 단위로 스케줄링한다.

### 멀티 프로세스가 있는데 왜 멀티 스레드를 사용하나요

하나의 프로세스 내에서 스레드는 프로세스 자원을 일부 공유한다. 따라서 첫번째, 스레드는 프로세스보다 자원을 덜 소모한다. 두번째, 프로세스 간 통신보다 스레드 간 통신이 쉽다. 세번째, 스레드는 프로세스보다 문맥 교환 비용이 작다.

> 스레드는 스택을 제외한 프로세스의 자원을 공유한다. 스택은 독립적으로 가진다.

### 멀티 스레드의 단점이 있나요?

멀티 스레드의 단점은 첫번째, 커널 영역을 공유하고 있으므로 하나의 스레드에 문제가 생기면 다른 스레드에도 문제가 생길 수 있다. 두번째, 자원을 공유하므로 임계구역에 대한 동기화가 필요하다.

### thread-safe에 대해 알고 있나요?

thread-safe는 멀티 스레드 환경에서 여러 개의 스레드가 공유 자원에 동시에 접근해도 프로그램 실행에 문제가 생기지 않는 것이다.

### thread-safe는 어떻게 구현할 수 있을까요?

공유 자원에 접근할 때 세마포어 등의 락을 사용해 상호 배제를 달성할 수 있다.

### 프로세스와 스레드의 차이는 무엇인가

프로세스와 스레드의 차이는 첫번째, 각각의 프로세스는 독립적으로 자원을 할당받지만 스레드는 스택을 제외하면 프로세스가 할당받은 자원을 공유한다. 두번째, 프로세스는 자원을 공유하기 위해 IPC를 사용하지만 스택은 데이터나 힙 영역으로 데이터를 주고받을 수 있다. 세번째, 스레드가 프로세스의 경량 버전이므로 생성과 삭제가 쉽고 싸다.

### 멀티 스레드를 사용하기 적합하거나 적합하지 않은 환경은?

첫번째 스레드 개수가 동적으로 빠르게 변하는 경우, 두번째 스레드 간에 데이터를 공유하는 경우 적절하다. 하지만 첫번째, 단일 프로세스로도 충분한 성능을 낼 수 있는 경우, 두번째 데이터 무결성이 중요한 경우는 적절하지 않다.

### 웹 서버에서 멀티 스레드 사용해보자

dispatcher 스레드가 네트워크 요청을 받는다. disaptcher가 대기 상태의 worker 스레드에게 요청을 전달한다. 깨어난 worker 스레드는 캐시와 디스크에서 페이지를 찾아 클라이언트에게 전달하고 새로운 요청을 대기하며 잠든다.

> 이때 많은 클라이언트와 연결이 되는 경우라면 dispatcher 스레드가 worker 스레드로부터 페이지를 전달받아서 클라이언트에게 전달하면 성능이 더 나을 수도 있다. 

## 프로세스 동기화

### 프로세스 동기화에 대해 설명해주세요

프로세스 동기화는 공유 데이터가 프로세스의 접근 순서에 관계없이 일관성을 유지하도록 하는 것이다.

### 경쟁 상태에 대해 설명해주세요

경쟁 상태는 공유 자원에 두 개 이상의 프로세스가 접근할 때 그 접근 순서에 따라 결과가 달라지는 상황을 뜻한다.

### 임계구역 문제를 해결하기 위해 만족해야하는 조건은 무엇인가요?

첫번째, 두 개 이상의 프로세스가 동시에 임계구역에 존재하지 않는다(상호 배제). 두번째, 임계구역이 비어있다면 진입할 수 있어야한다(progress). 세번째, 언젠가는 임계구역에 진입할 수 있어야한다(bounded waiting).

> 상호배제만으로도 경쟁 상태를 피할 수 있으나, 병렬 프로세스에서 발생하는 다른 문제들을 해결하기 위해서 나머지 두 조건도 필요로 한다.

### 임계구역 문제는 어떻게 해결할 수 있을까

커널 수준에서 원자적 연산을 제공하는 세마포어, 뮤텍스를 사용하여 해결할 수 있다.

### 뮤텍스 락이 무엇인가요

뮤텍스는 락과 언락의 상태를 가지는 객체이다. 상호 배제를 달성하기 위해 사용한다. 임계구역에 진입하려는 스레드가 락을 걸고 뮤텍스를 소유하며, 임계구역에서 나갈 때 락을 해제하여 뮤텍스를 반납한다.

### 세마포어가 무엇인가요

세마포어는 자원의 가용 개수를 나타내는 정수 변수이다. 세마포어를 사용하려는 프로세스나 스레드는 사용 가능한 자원이 없다면 wait하고 자원을 반납하는 프로세스나 스레드의 signal에 깨어난다.

### 뮤텍스 락과 스핀 락의 차이는 무엇인가

뮤텍스의 경우 스레드는 락을 획득할 수 없으면 블록되어 문맥 교환된다. 스핀 락의 경우 CPU 자원을 소유한 채 대기한다.

### 뮤텍스 락과 세마포어의 차이는 무엇인가?

첫번째, 뮤텍스 락은 한순간에 하나의 스레드만 뮤텍스를 소유할 수 있으나 세마포어는 동시에 여러 프로세스나 스레드가 소유할 수 있다. 두번째, 뮤텍스 락은 locking 메커니즘을 사용하여 락을 건 스레드만이 락을 해제할 수 있으나 세마포어는 signaling 메커니즘을 사용하여 락을 걸지 않은 스레드도 락을 해제할 수 있다.

## 데드락

### 데드락이 무엇인가요

데드락은 프로세스 집합에서 각각의 프로세스가 집합 내의 다른 프로세스만이 발생시킬 수 있는 이벤트를 기다리고 있는 상황이다.

### 데드락이 발생하는 조건에 대해서 말해보세요

데드락이 발생하는 조건은 상호배제, 점유대기(프로세스가 하나 이상의 자원을 잡은 채 다른 자원을 기다린다), 비선점, 순환대기(프로세스들이 각자 다른 프로세스들이 소유한 자원을 기다린다)이다.

### 데드락은 어떻게 처리할 수 있는가?

데드락 예방, 회피, 무시가 있다.

### 데드락은 어떻게 예방하는가?

데드락 예방은 데드락 발생 조건 중 하나를 제거하는 것이다.

상호 배제는 자원에 동시에 접근하는 것을 허용하여 제거한다. 점유 대기는 프로세스가 필요로 하는 모든 자원을 할당받아야 실행하도록 하여 제거한다. 비선점`은 우선순위가 높은 프로세스가 자원을 빼앗을 수 있도록 하여 제거한다. 순환 대기는 자원에 순서를 부여하여 해당 순서대로 자원을 요청하고 할당받도록 하여 제거한다.

### 데드락은 어떻게 회피하는가?

데드락 회피는 프로세스가 필요로 하는 모든 자원을 할당할 수 있는지 계산하고 이것이 가능한 경우에만 프로세스를 실행하는 것이다. 은행원 알고리즘을 사용하여 이 가용량을 계산할 수 있다.

> 은행원 알고리즘이란? 프로세스가 필요로 하는 자원의 총량에서 현재 프로세스가 할당받은 자원의 총량을 제한 것과 현재 프로세스에게 할당할 수 있는 자원을 비교하는 알고리즘이다.

## 메모리 관리

### RAM과 하드디스크는 왜 작업 속도가 차이날까요?

RAM은 주소를 사용하여 기억 장소에 직접적으로 접근할 수 있어 어떤 데이터이든 접근하는 시간이 동일하다. 하드디스크는 접근하기까지 탐색 시간(헤드를 트랙으로 이동하는 시간)과 회전 지연 시간(섹터가 헤드 아래로 회전되어 오기까지의 시간)을 요한다.

> RAM의 접근 방식을 무작위 접근이라고 하며, 이러한 특징을 반영하여 Random Access Memory라고 부르는 것이다.

### 캐시는 무엇이고 캐시는 왜 사용하는가?

캐시는 CPU 내부에 있는 고속의 기억 장치이다. 메인 메모리 작업 속도가 CPU의 작업 속도에 비해 많이 느리기 때문에, 성능 저하를 막기 위해 사용한다.

### 비트, 바이트, 워드, 블록에 대해 설명해주세요?

- 비트(bit)는 컴퓨터에서 데이터를 나타내는 최소 단위이다.
- 바이트(byte)는 컴퓨터에서 데이터를 처리하는 최소 단위이다. 1byte는 8bit이다
- 워드(word)는 CPU가 한 번에 처리할 수 있는 데이터의 크기이다. 32bit CPU에서 1word는 32bit(4byte)이고, 64bit CPU에서 1word는 64bit(8byte)이다.
- 블록(block)은 캐시에서 한 번에 저장하거나 쓰는 데이터의 단위이다.

### 캐시의 지역성에 대해 설명해주세요?

캐시는 지역성에 따라 참조한 데이터뿐만 아니라 인접한 데이터까지 묶어 블록 단위로 저장한다. 캐시의 지역성은 참조 지역성으로, 참조되었던 데이터나 그와 관계가 있는 데이터가 가까운 미래에 다시 참조될 가능성이 높은 특성을 가리킨다. 참조 지역성에는 첫번째, 한 번 참조한 데이터는 다시 참조할 가능성이 높다는 시간 지역성과 두번째, 참조된 데이터에 인접한 데이터는 미래에 참조할 가능성이 높다는 공간 지역성, 마지막으로 데이터가 순차적으로 참조될 가능성이 높다는 순차적 지역성이 있다. 

>  순차적 지역성은 공간 지역성의 특별한 경우로 보기도 한다.

### 캐시 교체 알고리즘에는 무엇이 있는가?

FIFO(First In First Out)은 적재된 지 가장 오래된 캐시 블록을 비운다. LRU(Least Recently Used)는 참조된 지 가장 오래된 캐시 블록을 비운다. LFU(Least Frequency Used)는 가장 적게 참조된 캐시 블록을 비운다.

### LRU 캐시는 어떻게 구현할 수 있을까요?

캐시를 해시맵으로 구현한다고 가정하겠다. 각 블록마다 참조된 시점을 기록한다. 블록에 접근할 때마다 참조된 시점을 저장한 필드를 업데이트하겠다. 캐시가 꽉 차면 이 필드로 참조한 지 가장 오래된 블록을 찾아 비우겠다. 

### C 언어로 작성된 프로그램 코드가 디스크에 적재되어있다. 이 코드가 실행되기까지의 과정을 서술하라.

1. 전처리: 전처리기-소스 코드의 전처리문을 다른 코드로 변환
2. 컴파일: 컴파일러-소스코드를 어셈블리 코드로 변환
3. 어셈블: 어셈블러-어셈블리 코드를 오브젝트 코드로 변환
4. 링킹: 링커-라이브러리 코드까지 가져와서 실행 파일 만듦
5. 로딩: 로더-할당된 메모리에 실행 파일 복사하여 이미지 만듦
6. 실행: CPU가 메모리에서 데이터 읽어와 실행

### MMU는 어떤 역할을 하는가?

MMU(Memory Management Unit)은 CPU가 프로세스를 실행하기 위해 메모리에 접근하는 것을 관리한다. 첫번째, 동적으로 논리 주소를 물리 주소로 변환하거나 두번째, 프로세스가 독립적인 주소 공간을 유지하도록 메모리를 보호한다.

### MMU는 어떻게 메모리를 보호하는가?

프로세스를 연속적인 메모리에 배치한다고 하자. `base` 레지스터가 프로세스의 시작 주소를, `limit` 레지스터가 프로세스의 크기를 저장한다. CPU가 접근하려는 메모리의 주소가 `base` 레지스터의 값보다 같거나 크고, `limit`과 `base`를 더한 값보다 작으면 유효한 주소이다. 해당 주소 범위를 넘으면 trap을 발생시켜 프로세스를 종료시킨다.

### 단편화란 무엇인가요?

단편화는 메모리에는 빈 공간에 충분하나 이를 프로세스에게 할당할 수 없는 문제를 말한다. 내부 단편화는 프로세스에게 너무 큰 공간을 할당하여 남은 공간이 낭비되는 경우이다. 외부 단편화는 프로세스에게 연속적인 공간을 할당할 수 없는 경우이다.

### 외부 단편화는 어떻게 해결할 수 있을까?

외부 단편화는 첫번째, 주기적으로 모든 빈 공간을 하나로 모으거나(압축) 두번째, 인접한 빈 공간을 합쳐 큰 빈 공간을 만들어(병합) 해결하겠다.

### 메모리 할당 방식을 설명하라

메모리 할당 방식은 연속 할당 방식과 불연속 할당 방식으로 나눌 수 있다. 연속 할당 방식은 프로세스를 연속적인 메모리에 할당하는 것으로 모든 프로세스가 동일한 크기의 메모리를 할당받는 고정 분할 방식과 프로세스에게 적절한 크기의 메모리를 할당받는 가변 분할 방식으로 나뉜다. 고정 분할 방식의 경우 내부 단편화가, 가변 분할 방식은 외부 단편화가 발생할 수 있다. 불연속 할당 방식은 프로세스를 불연속적인 메모리에 분산하여 할당하는 것으로 이때 메모리를 동일한 크기로 자르면 페이징, 가변 크기로 자르면 세그먼테이션이라고 한다.

### 스와핑은 무엇이고 단점은 무엇인가?

스와핑은 프로세스의 전체 이미지를 메모리에 적재하여 실행하다가 실행되지 않거나 메모리 공간이 부족해지면 디스크의 SWAP 영역으로 swap out하는 메모리 관리 기법이다. 스와핑의 단점은 첫번째 단편화가 생길 수 있다는 것이고 두번째, 물리 메모리의 실제 크기에 영향을 받는다는 것이다.

> 스와핑은 연속 할당 방식을 사용하는 메모리 기법이다.

## 가상 메모리

### 가상 메모리가 무엇이고 단점은 무엇인가?

가상 메모리는 당장 실행에 필요한 프로세스 수행 이미지 일부만 메모리에 적재하여 실행하고 나머지는 디스크의 SWAP 영역에 적재하는 메모리 관리 기법이다. 이때 프로세스는 무한한 크기의 가상 메모리와 CPU 자원을 독점하고 있다는 전제 하에 0번지부터 작성된다. 가상 메모리의 단점은 첫번째, 가상 주소와 물리 주소를 매핑하는 별도의 저장 공간(페이지 테이블)을 필요로 한다. 두번째, 가상 메모리를 사용하지 않을 때보다(물리 메모리 접근) 메모리 접근 횟수가 늘어난다(페이지 테이블 접근 -> 물리 메모리 접근).

> 가상 메모리는 불연속 할당 방식을 사용하는 메모리 기법이다. 이때 페이징 기법을 사용하는 가상 메모리를 요구 페이징, 세그먼테이션 기법을 사용하는 가상 메모리를 요구 세그먼테이션이라고 한다.

### 가상 메모리를 사용했을 때의 장점은 무엇인가?

가상 메모리의 장점은 첫번째, 프로세스는 실제 물리 메모리의 크기에 제약을 받지 않고 실행될 수 있다. 두번째, 가상 주소를 사용하므로 프로세스의 주소 공간을 보호할 수 있다. 세번째, 페이지별로 보호 기능을 제공한다. 네번째, 메모리를 공유할 수 있다.

### 가상 주소에 대해 설명해주세요

가상 주소는 물리 메모리의 프레임에 대응하는 가상 메모리의 페이지를 식별하는 페이지 번호와 바이트 오프셋으로 이루어진다. MMU는 가상 주소를 물리 주소로 동적 변환하기 위해 DRAM에 페이지 테이블을 유지한다.

### 요구 페이징 기법에서 프로세스가 가상 주소를 참조하면 어떤 일이 발생하는가?

첫번째, MMU가 가상 주소를 페이지 번호와 바이트 오프셋으로 구분한다. 두번째, MMU는 DRAM의 페이지 테이블에서 페이지 번호를 인덱스로 엔트리를 찾는다. valid 비트가 0이면 페이지 폴트를 발생시켜 디스크의 SWAP 영역에서 페이지를 찾아 메모리에 적재하고 페이지 테이블 엔트리를 갱신한다. 이때 메모리가 꽉 찬 상태라면 페이지 교체 알고리즘을 사용하여 대상 페이지를 선택하고 내보낸다. valid 비트가 1이면 페이지 번호를 프레임 번호로 바꾸고 바이트 오프셋을 더하여 물리 주소로 변환한다. 세번째, 물리 주소로 메모리에 접근하여 데이터를 가져온다.

### 주소 변환 속도를 높이려면 어떻게 해야할까요?

CPU 내부에 페이지 테이블에 대한 캐시(TLB;Translation Lookaside Buffer)를 둔다.

### 페이지 테이블의 크기를 줄일 수 있을까요?

첫번째, 다단계 페이지 테이블을 사용하여 빈 주소 공간에 대해서는 페이지 테이블 엔트리를 유지하지 않을 수 있다. 두번째, 역 페이지 테이블을 사용하여 가상 주소 공간이 아니라 물리 메모리에 비례하는 크기로 유지할 수 있다.

### 역 페이지 테이블에 어떤 단점이 있을까요?

가상 주소를 물리 주소로 변환하기 위해 테이블을 전체 탐색해야한다.

### 역 페이지 테이블의 단점을 개선해볼 수 있을까요?

가상 주소를 해싱한 값을 키로 사용하고 같은 해시 값을 가지는 페이지를 링크드 리스트로 만들 수 있겠다.

### 페이지 폴트와 스레싱에 대해 설명해주세요

페이지 폴트는 프로세스가 실행되기 위해 필요한 페이지가 메모리에 적재되어있지 않은 현상을 말한다. 이 경우 디스크에 접근하여 페이지를 가져와 메모리에 적재해야하므로 페이지 폴트 인터럽트가 발생한다. 스레싱은 페이지 폴트가 자주 발생하여, 결과적으로 CPU 이용률이 감소해 작업이 멈춘 듯 보이는 상태이다.

> 메모리에 올라간 프로세스의 수가 과도하게 많은 경우 프로세스는 원활히 수행될 정도의 메모리를 할당받지 못한다. 이때 페이지 폴트가 발생하면 페이지 교체를 위해 디스크 I/O가 발생하고 다른 프로세스로 문맥 교환된다. 그런데 다른 프로세스들 역시 동일한 이유에서 페이지 폴트를 발생시킨다면 CPU는 대부분의 시간을 페이지 교체에 사용하고 프로세스를 수행하지 못하게 된다.

### 스레싱은 어떻게 예방할 수 있는가?

현재 프로세스가 원할히 실행되기 위한 페이지의 집합을 모두 적재해야 프로세스를 실행하도록 하는 워킹 셋 알고리즘이나 페이지 폴트 발생율에 따라 메모리 할당량을 조절하는 PFF(Page Fault Frequency) 알고리즘을 사용할 수 있다.